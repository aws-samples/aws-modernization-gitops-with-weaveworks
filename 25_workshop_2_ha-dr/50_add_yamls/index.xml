<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Manage your cluster using GitOps on Weaveworks Introduction to GitOps w/ AWS EKS</title>
    <link>/25_workshop_2_ha-dr/50_add_yamls.html</link>
    <description>Recent content in Manage your cluster using GitOps on Weaveworks Introduction to GitOps w/ AWS EKS</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-US</language>
    
	<atom:link href="/25_workshop_2_ha-dr/50_add_yamls/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Install the NGINX Ingress Controller</title>
      <link>/25_workshop_2_ha-dr/50_add_yamls/10_alb_ingress.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/25_workshop_2_ha-dr/50_add_yamls/10_alb_ingress.html</guid>
      <description>There are multiple ways to enable access via Ingress to the Services running in your cluster. You can use Application Load Balancers using AWS own Load Balancer Controller which will create an Application Load Balancer for every Ingress in your cluster, but in this case we are going to use the NGINX Ingress Controller, which works with a single Network Load Balancer created for the Ingress Controller Service.
We are choosing this method in order to maintain a single and consistent desired state applicable to both clusters.</description>
    </item>
    
    <item>
      <title>Introducing Hello Kubernetes</title>
      <link>/25_workshop_2_ha-dr/50_add_yamls/20_hello_kubernetes_introduction.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/25_workshop_2_ha-dr/50_add_yamls/20_hello_kubernetes_introduction.html</guid>
      <description>Hello Kubernetes is a very simple web application created by Paul Bouwer, open source and available in GitHub.
For our workshop, we will be using Hello Kubernetes to quickly demonstrate how load balancing and high availability can be simply implemented with ingresses and Kubernetes.
Our configuration will enable internal Kubernetes load balancing and scaling. Optionally, AWS Route 53 can be used to balance between your actual clusters in different regions.</description>
    </item>
    
    <item>
      <title>Deploy the Hello Kubernetes Application</title>
      <link>/25_workshop_2_ha-dr/50_add_yamls/21_hello_kubernetes_deploy.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/25_workshop_2_ha-dr/50_add_yamls/21_hello_kubernetes_deploy.html</guid>
      <description>One of the principles of GitOps states that the only way to interact with a cluster should be by modifying the state declared in code. Following that principle means we will not be performing any action with kubectl or otherwise interacting with either of our clusters directly.
You are now going to deploy the Hello Kubernetes application and associated resources in both of your clusters, by pushing manifests into your repository.</description>
    </item>
    
    <item>
      <title>Enable Hello Kubernetes to Scale Automatically</title>
      <link>/25_workshop_2_ha-dr/50_add_yamls/22_hello_kubernetes_hpa.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/25_workshop_2_ha-dr/50_add_yamls/22_hello_kubernetes_hpa.html</guid>
      <description>A very useful feature in Kubernetes is to enable auto-scaling. This is accomplished by created a Horizontal Pod Autoscaler (HPA) object that is targeted at a specific pod. Each HPA has criteria that Kubernetes uses in order add pods to the running deployment. This HPA will scale the podinfo deployment to a minimum of 2 replicas, and a maximum of 4 replicas.
Create a file called clusters/eks-ha/hello-kubernetes/hpa.yaml in your git repository:</description>
    </item>
    
    <item>
      <title>Check Everything</title>
      <link>/25_workshop_2_ha-dr/50_add_yamls/25_check_everything.html</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/25_workshop_2_ha-dr/50_add_yamls/25_check_everything.html</guid>
      <description>Let&amp;rsquo;s inspect what we have deployed to the cluster by pushing the various manifests into the repo. Using the kubectl get all -n &amp;lt;namespace&amp;gt; command, let&amp;rsquo;s look at what has been automatically created in each namespace.
You will now have three new namespaces:
 flux-system which holds all the resources that Flux v2 runs to automatically reconcile your cluster against one or more repos
NAME READY STATUS RESTARTS AGE pod/helm-controller-85bfd4959d-m9f98 1/1 Running 0 11h pod/kustomize-controller-7d5959c758-k94sm 1/1 Running 0 11h pod/notification-controller-758d759586-cz5bx 1/1 Running 0 11h pod/source-controller-6d986bbb7f-486qv 1/1 Running 0 11h NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/notification-controller ClusterIP 10.</description>
    </item>
    
  </channel>
</rss>